# 学习率（learning_rate）
## 问题
### 什么是学习率
在机器学习领域，训练模型的过程就如同开车寻找宝藏，而这个 “宝藏” 就是最优的模型参数。其中，梯度如同车上的导航，它会为你指明前进的方向；

而学习率则类似于汽车的油门，它决定了模型参数每次按照梯度指引方向进行更新时的步长，简单来说，就是车行驶的速度。

学习率的具体体现就是下面的α
$$k = k - \alpha\frac{\partial loss(h_w)}{\partial k}$$

### 为什么不能没有学习率
如果没有学习率，模型参数更新就失去了 “速度” 的概念。

要是没有学习率，车就只能按一个固定速度跑，不管什么路况。但现实里，不同的路况（也就是不同的数据集和模型结构），肯定需要不同的车速。比如数据集特别大，就像开高速，车速得快点；要是数据集很复杂，像走乡道弯弯绕绕，车速就得慢点儿，不然一不小心掉沟里。

在模型训练中，不同的数据集和模型结构，就如同不同的路况，需要不同的 “车速” 来调整参数，这样模型才能更好地学习数据特征，进而找到最优解。因此，学习率在模型训练中是不可或缺的。

### 学习率太大可能导致的问题
错过最优解：当学习率过大时，就像在城市中开车还将油门踩到底。模型参数更新的步伐过大，会在最优解附近来回 “跳跃”，无法精准地达到最佳状态，很容易错过最合适的参数，最终导致模型无法收敛。
模型不稳定：过大的学习率可能使模型在训练过程中变得极不稳定，损失函数波动剧烈，甚至会出现不下降反而上升的情况，这使得模型无法正常训练。

### 学习率太小可能导致的问题
训练时间过长：学习率太小就如同开车时一直缓慢爬行。模型参数更新的步伐极小，需要耗费大量的时间和计算资源，才能慢慢靠近最优解，这无疑会大大增加训练的时间成本。
陷入局部最优：由于更新步长过小，模型可能被困在局部最优解中无法自拔。就像在寻找宝藏的途中，明明不远处就有更好的宝藏（全局最优解），但因为步子太小，始终无法走出当前的小区域，最终只能得到一个并非最佳的结果。

后面有空再写，是一些实战经验和碰到的实际问题